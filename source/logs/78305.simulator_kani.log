cpu-bind=MASK - nlpgpu04, task  0  0 [4202]: mask 0x3f0300003f03 set
cpu-bind=MASK - nlpgpu04, task  0  0 [4219]: mask 0x3f0300003f03 set
cpu-bind=MASK - nlpgpu08, task  1  0 [34077]: mask 0xff000000ff set
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards:  12%|█▎        | 1/8 [00:00<00:00,  9.45it/s]Loading checkpoint shards:  25%|██▌       | 2/8 [00:00<00:00,  9.41it/s]Loading checkpoint shards:  38%|███▊      | 3/8 [00:00<00:00,  9.35it/s]Loading checkpoint shards:  50%|█████     | 4/8 [00:00<00:00,  9.33it/s]Loading checkpoint shards:  62%|██████▎   | 5/8 [00:00<00:00,  9.35it/s]Loading checkpoint shards:  75%|███████▌  | 6/8 [00:00<00:00,  9.26it/s]Loading checkpoint shards:  88%|████████▊ | 7/8 [00:00<00:00,  9.27it/s]Loading checkpoint shards: 100%|██████████| 8/8 [00:00<00:00,  9.40it/s]Loading checkpoint shards: 100%|██████████| 8/8 [00:00<00:00,  9.35it/s]
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 2/8 [00:00<00:00, 11.15it/s]Loading checkpoint shards:  50%|█████     | 4/8 [00:00<00:00, 11.32it/s]Loading checkpoint shards:  75%|███████▌  | 6/8 [00:00<00:00, 11.39it/s]Loading checkpoint shards: 100%|██████████| 8/8 [00:00<00:00, 11.51it/s]Loading checkpoint shards: 100%|██████████| 8/8 [00:00<00:00, 11.43it/s]
/home1/a/adilsha/miniconda3/lib/python3.12/site-packages/transformers/generation/utils.py:1220: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.
  warnings.warn(
The 'max_batch_size' argument of HybridCache is deprecated and will be removed in v4.46. Use the more precisely named 'batch_size' argument instead.
Starting from v4.46, the `logits` model output will have the same type as the model (except at train time, where it will always be FP32)
----------------------- 

prompt 

Once upon a time in a distant land, there was a brave knight who

----------------------- 

response 

was on a quest
Model Response:
was on a quest
srun: Job step aborted: Waiting up to 32 seconds for job step to finish.
slurmstepd: error: *** JOB 78305 ON nlpgpu04 CANCELLED AT 2024-10-05T02:57:00 ***
